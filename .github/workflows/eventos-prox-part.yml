name: EventProxPart (FlowAgility eventos + participantes) Beta

on:
  workflow_dispatch:
    inputs:
      limit_events:
        description: "Máximo de eventos a procesar (0 = sin límite)"
        required: false
        default: "2"
      max_runtime_min:
        description: "Corte ordenado a los N minutos (0 = sin límite)"
        required: false
        default: "15"
  schedule:
    - cron: "40 3 * * *"

permissions:
  contents: read

concurrency:
  group: eventproxpart-${{ github.ref }}
  cancel-in-progress: false

jobs:
  run-scrape:
    runs-on: ubuntu-24.04
    timeout-minutes: 45

    env:
      TZ: Europe/Madrid
      PYTHONUNBUFFERED: "1"
      PIP_DISABLE_PIP_VERSION_CHECK: "1"
      HEADLESS: "true"
      INCOGNITO: "true"
      OUT_DIR: "./output"
      MAX_SCROLLS: "8"
      SCROLL_WAIT_S: "2.0"
      MAX_EVENTS_FOR_TESTING: "${{ github.event.inputs.limit_events || '2' }}"
      MAX_RUNTIME_MIN: "${{ github.event.inputs.max_runtime_min || '15' }}"

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y wget curl unzip

      - name: Install Chrome Browser
        run: |
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable
          google-chrome-stable --version

      - name: Install ChromeDriver
        run: |
          CHROME_VERSION=$(google-chrome-stable --version | grep -oP '\d+\.\d+\.\d+\.\d+' | cut -d. -f1-3)
          CHROMEDRIVER_VERSION=$(curl -s "https://chromedriver.storage.googleapis.com/LATEST_RELEASE_$CHROME_VERSION")
          wget -q "https://chromedriver.storage.googleapis.com/$CHROMEDRIVER_VERSION/chromedriver_linux64.zip"
          unzip -q chromedriver_linux64.zip
          sudo mv chromedriver /usr/local/bin/
          sudo chmod +x /usr/local/bin/chromedriver
          rm chromedriver_linux64.zip
          chromedriver --version

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install selenium beautifulsoup4 python-dotenv

      - name: Create output directory
        run: |
          mkdir -p "${{ env.OUT_DIR }}"

      - name: Create .env file from secrets
        run: |
          {
            echo "FLOW_EMAIL=${{ secrets.FLOW_EMAILRQ }}"
            echo "FLOW_PASS=${{ secrets.FLOW_PASSRQ }}"
            echo "HEADLESS=${{ env.HEADLESS }}"
            echo "INCOGNITO=${{ env.INCOGNITO }}"
            echo "OUT_DIR=${{ env.OUT_DIR }}"
            echo "MAX_SCROLLS=${{ env.MAX_SCROLLS }}"
            echo "SCROLL_WAIT_S=${{ env.SCROLL_WAIT_S }}"
          } > .env
          echo "=== ARCHIVO .env CONFIGURADO ==="
          sed 's/FLOW_PASS=.*/FLOW_PASS=***/' .env

      - name: Run EventosProxParticipantesDeep.py scraper
        timeout-minutes: 30
        env:
          FLOW_EMAIL: "${{ secrets.FLOW_EMAILRQ }}"
          FLOW_PASS: "${{ secrets.FLOW_PASSRQ }}"
        run: |
          echo "=== INICIANDO SCRAPER ==="
          echo "Script: EventosProxParticipantesDeep.py"
          echo "Límite de eventos: ${{ env.MAX_EVENTS_FOR_TESTING }}"
          
          if [ ! -f "EventosProxParticipantesDeep.py" ]; then
            echo "❌ ERROR: El archivo EventosProxParticipantesDeep.py no existe"
            ls -la *.py
            exit 1
          fi
          
          python EventosProxParticipantesDeep.py --module all
          SCRAPER_EXIT_CODE=$?
          echo "Scraper finalizado con código: $SCRAPER_EXIT_CODE"

      - name: Analyze JSON content
        run: |
          echo "=== ANÁLISIS DE CONTENIDO JSON ==="
          
          # Método más simple sin heredoc
          echo 'import json
import os
import sys

def analyze_events():
    out_dir = os.environ.get("OUT_DIR", "./output")
    events_file = os.path.join(out_dir, "01events.json")
    info_file = os.path.join(out_dir, "02info.json")
    
    if os.path.exists(events_file):
        print("📊 Análisis de 01events.json:")
        try:
            with open(events_file, "r", encoding="utf-8") as f:
                data = json.load(f)
            print(f"   Número de eventos: {len(data)}")
            for i, event in enumerate(data[:3]):
                print(f"   Evento {i+1}: {event.get('nombre', 'N/A')}")
        except Exception as e:
            print(f"   Error: {e}")
    else:
        print("❌ 01events.json no encontrado")
    
    if os.path.exists(info_file):
        print("📊 Análisis de 02info.json:")
        try:
            with open(info_file, "r", encoding="utf-8") as f:
                data = json.load(f)
            events_with_participants = [e for e in data if e.get("numero_participantes", 0) > 0]
            total_participants = sum(e.get("numero_participantes", 0) for e in data)
            print(f"   Eventos con participantes: {len(events_with_participants)}")
            print(f"   Total participantes: {total_participants}")
        except Exception as e:
            print(f"   Error: {e}")
    else:
        print("❌ 02info.json no encontrado")

if __name__ == "__main__":
    analyze_events()' > analyze_events.py

          python analyze_events.py

      - name: Compress JSON files for backup
        run: |
          echo "=== COMPRIMIENDO ARCHIVOS PARA BACKUP ==="
          for json_file in "${{ env.OUT_DIR }}"/*.json; do
            if [ -f "$json_file" ]; then
              gzip -9 -k "$json_file"
              original_size=$(stat -c%s "$json_file")
              compressed_size=$(stat -c%s "${json_file}.gz")
              echo "✅ $(basename "$json_file") comprimido"
            fi
          done

      - name: Create backup and upload artifacts
        run: |
          mkdir -p ./backup
          cp -r "${{ env.OUT_DIR }}" ./backup/ || echo "No se pudo crear backup"

      - name: Upload JSON files as artifact
        uses: actions/upload-artifact@v4
        with:
          name: scraper-json-output
          path: |
            ${{ env.OUT_DIR }}/*.json
            ${{ env.OUT_DIR }}/*.gz
          retention-days: 7
          if-no-files-found: warn

      - name: Final summary
        run: |
          echo "=== RESUMEN FINAL ==="
          echo "Límite de eventos: ${{ env.MAX_EVENTS_FOR_TESTING }}"
          echo "Directorios generados:"
          find . -name "output" -o -name "backup" -type d | head -10

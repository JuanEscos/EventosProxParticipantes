name: EventProxPart (FlowAgility eventos + participantes)

on:
  workflow_dispatch:
    inputs:
      limit_events:
        description: "Máximo de eventos a procesar (0 = sin límite)"
        required: false
        default: "35"
      max_runtime_min:
        description: "Cortar ordenadamente a los N minutos (0 = sin límite)"
        required: false
        default: "25"
  schedule:
    # Nota: el cron es en UTC. 03:40 UTC ~ 05:40 Europe/Madrid (según DST)
    - cron: "40 3 * * *"

permissions:
  contents: read

concurrency:
  group: eventproxpart-${{ github.ref }}
  cancel-in-progress: false

jobs:
  run-scrape:
    runs-on: ubuntu-24.04
    timeout-minutes: 90

    env:
      TZ: Europe/Madrid
      PYTHONUNBUFFERED: "1"
      PIP_DISABLE_PIP_VERSION_CHECK: "1"
      # ---- Scraper ENV por defecto (puedes ajustarlos aquí o vía workflow_dispatch) ----
      HEADLESS: "true"
      INCOGNITO: "true"
      OUT_DIR: "./output"
      MAX_SCROLLS: "12"
      SCROLL_WAIT_S: "2.0"
      LIMIT_EVENTS: "${{ github.event.inputs.limit_events || '35' }}"
      MAX_RUNTIME_MIN: "${{ github.event.inputs.max_runtime_min || '25' }}"
      # Throttling y resume (02EventosProxParticipantesGitHubGPT.py)
      THROTTLE_EVENT_S: "3.0"
      THROTTLE_PAGE_MIN_S: "1.2"
      THROTTLE_PAGE_MAX_S: "2.5"
      THROTTLE_TOGGLE_MIN_S: "0.9"
      THROTTLE_TOGGLE_MAX_S: "2.2"
      AUTO_SAVE_EVERY: "10"
      RESUME: "true"
      RESUME_FILE: ""
      # Credenciales (usar Secrets del repo/org)
      FLOW_EMAILRq: "${{ secrets.FLOW_EMAILRQ }}"
      FLOW_PASSRq: "${{ secrets.FLOW_PASSRQ }}"

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install Chrome
        uses: browser-actions/setup-chrome@v1
        with:
          chrome-version: stable

      - name: Install chromedriver
        uses: nanasess/setup-chromedriver@v2
        with:
          # se ajusta automáticamente a la versión instalada de Chrome
          # chromedriver-version: latest
          # no es necesario especificar versión salvo que quieras fijarla
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Show Chrome versions
        run: |
          google-chrome --version || true
          chromedriver --version || true

      - name: Install Python deps
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          else
            pip install selenium webdriver-manager beautifulsoup4 python-dotenv
          fi

      - name: Prepare output dir
        run: |
          mkdir -p "${OUT_DIR}"
          echo "OUT_DIR contents (before):"
          ls -la "${OUT_DIR}" || true

      - name: Run Python scraper (events + participants)
        # Subimos el límite de tiempo de ESTE paso (además del job)
        timeout-minutes: 60
        env:
          # Repetimos env clave por si este paso se corre aislado
          HEADLESS: "${{ env.HEADLESS }}"
          INCOGNITO: "${{ env.INCOGNITO }}"
          OUT_DIR: "${{ env.OUT_DIR }}"
          MAX_SCROLLS: "${{ env.MAX_SCROLLS }}"
          SCROLL_WAIT_S: "${{ env.SCROLL_WAIT_S }}"
          LIMIT_EVENTS: "${{ env.LIMIT_EVENTS }}"
          MAX_RUNTIME_MIN: "${{ env.MAX_RUNTIME_MIN }}"
          THROTTLE_EVENT_S: "${{ env.THROTTLE_EVENT_S }}"
          THROTTLE_PAGE_MIN_S: "${{ env.THROTTLE_PAGE_MIN_S }}"
          THROTTLE_PAGE_MAX_S: "${{ env.THROTTLE_PAGE_MAX_S }}"
          THROTTLE_TOGGLE_MIN_S: "${{ env.THROTTLE_TOGGLE_MIN_S }}"
          THROTTLE_TOGGLE_MAX_S: "${{ env.THROTTLE_TOGGLE_MAX_S }}"
          AUTO_SAVE_EVERY: "${{ env.AUTO_SAVE_EVERY }}"
          RESUME: "${{ env.RESUME }}"
          RESUME_FILE: "${{ env.RESUME_FILE }}"
          FLOW_EMAILRq: "${{ env.FLOW_EMAILRq }}"
          FLOW_PASSRq: "${{ env.FLOW_PASSRq }}"
        run: |
          echo "=== EJECUTANDO SCRAPER ==="
          python ./02EventosProxParticipantesGitHubGPT.py --module all
          echo "=== SCRAPER COMPLETADO ==="

      - name: List output
        if: always()
        run: |
          echo "OUT_DIR contents (after):"
          ls -la "${OUT_DIR}" || true
          echo ""
          echo "Disk usage:"
          du -h "${OUT_DIR}" || true

      - name: Upload artifact (output)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: output-${{ github.run_id }}
          path: |
            ${{ env.OUT_DIR }}/
          if-no-files-found: warn
          retention-days: 7
